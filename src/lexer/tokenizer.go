package lexer

import "fmt"

func Tokenize(source string) []Token {
	lex := createLexer(source)

	for !lex.at_eof() {
		matched := false

		for _, pattern := range lex.patterns {
			location := pattern.regex.FindStringIndex(lex.remainder())

			if location != nil && location[0] == 0 {
				pattern.handler(lex, pattern.regex)
				matched = true
				break
			}
		}

		if !matched {
			panic(fmt.Sprintf("lexer error: unrecognized token near '%v'", lex.remainder()))
		}
	}

	lex.push(CreateToken(EOF, "EOF"))
	return lex.Tokens
}
